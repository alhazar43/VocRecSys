{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "n = 20\n",
    "\n",
    "\n",
    "pg = [chr(65 + i) for i in range(n)] \n",
    "\n",
    "p_score = {p: np.random.randint(40, 100, size=6) for p in pg}\n",
    "p_salary = {p: np.random.randint(5, 10) for p in pg}\n",
    "p_vers = {p: np.random.randint(5, 10) for p in pg}\n",
    "p_elig = {p: np.random.randint(50, 90) for p in pg}\n",
    "\n",
    "\n",
    "u_score = np.random.randint(50, 100, size=6)\n",
    "u_elig = np.random.randint(50, 90)\n",
    "\n",
    "# User preferences (weights)\n",
    "w_salary = 0.6\n",
    "w_vers = 0.3\n",
    "w_elig = 0.1  \n",
    "\n",
    "q_dict = {program: 0 for program in pg}\n",
    "\n",
    "\n",
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "w_feed = 0.5 \n",
    "\n",
    "\n",
    "episodes = 5000\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    \n",
    "    p = random.choice(pg)\n",
    "    \n",
    "    similarity = np.dot(u_score, p_score[p]) / (np.linalg.norm(u_score) * np.linalg.norm(p_score[p]))\n",
    "\n",
    "    elig_score = u_elig / p_elig[p]\n",
    "\n",
    "    r_salary = p_salary[p] * similarity\n",
    "    r_vers = p_vers[p] * similarity\n",
    "    r_elig = elig_score * 10 \n",
    "\n",
    "\n",
    "    reward = (w_salary * r_salary + \n",
    "              w_vers * r_vers + \n",
    "              w_elig * r_elig)\n",
    "\n",
    "\n",
    "    max_q = max(q_dict.values())\n",
    "    curr_q = q_dict[p]\n",
    "    new_q = (1 - lr) * curr_q + lr * (reward + gamma * max_q)\n",
    "    q_dict[p] = new_q\n",
    "\n",
    "top_n = 5 \n",
    "rec_p = sorted(q_dict, key=q_dict.get, reverse=True)[:top_n]\n",
    "\n",
    "print(\"Top recommended programs\")\n",
    "for i, p in enumerate(rec_p, 1):\n",
    "    print(f\"{i}. Program {p}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_feed = {}\n",
    "for p in rec_p:\n",
    "    while True:\n",
    "        try:\n",
    "            score = int(input(f\"Rate Program {p} (0-5): \"))\n",
    "            if 0 <= score <= 5:\n",
    "                u_feed[p] = score\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a valid score between 0 and 5.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid integer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust Q-values based on user feedback\n",
    "for p, score in u_feed.items():\n",
    "    if score == 0:\n",
    "        # Strong disagreement: Heavily penalize the Q-value\n",
    "        q_dict[p] -= w_feed * 10\n",
    "    else:\n",
    "        # Adjust Q-value based on the user's score (higher score = higher preference)\n",
    "        q_dict[p] += w_feed * score\n",
    "\n",
    "# Recommend the top N programs again after incorporating user feedback\n",
    "revised = sorted(q_dict, key=q_dict.get, reverse=True)[:top_n]\n",
    "\n",
    "print(\"\\nTop recommended programs after incorporating user feedback:\")\n",
    "for i, p in enumerate(revised, 1):\n",
    "    print(f\"{i}. Program {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize program details\n",
    "n_p = 20\n",
    "progs = [chr(65 + i) for i in range(n_p)]\n",
    "p_s = {p: np.random.randint(40, 100, size=6) for p in progs}\n",
    "p_sal = {p: np.random.randint(5, 10) for p in progs}\n",
    "p_vers = {p: np.random.randint(5, 10) for p in progs}\n",
    "p_elg = {p: np.random.randint(50, 90) for p in progs}\n",
    "\n",
    "\n",
    "u_s = np.random.randint(50, 100, size=6).astype(float)\n",
    "u_elg = float(np.random.randint(50, 90))  \n",
    "w_sal = 0.6\n",
    "w_vers = 0.3\n",
    "w_elg = 0.1\n",
    "\n",
    "q_vals = {p: 0.0 for p in progs}\n",
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "f_adj = 0.5\n",
    "epsilon_threshold = 0.01\n",
    "top_n = 5\n",
    "\n",
    "\n",
    "questions_pool = np.random.rand(1000)\n",
    "asked_questions = []\n",
    "\n",
    "def ask_qs():\n",
    "    global asked_questions, u_s\n",
    "    selected_questions = random.sample(list(questions_pool), 6)\n",
    "    for weight in selected_questions:\n",
    "        answer = int(input(f\"Answer question (0-5): \"))\n",
    "        answer = max(0, min(answer, 5)) \n",
    "        u_s += answer * weight  \n",
    "    asked_questions.extend(selected_questions)\n",
    "    return u_s\n",
    "\n",
    "def update_q_vals():\n",
    "    epsilon = 0\n",
    "    for p in progs:\n",
    "        sim = np.dot(u_s, p_s[p]) / (np.linalg.norm(u_s) * np.linalg.norm(p_s[p]))\n",
    "        elg_impact = u_elg / p_elg[p]\n",
    "        r_sal = p_sal[p] * sim\n",
    "        r_vers = p_vers[p] * sim\n",
    "        r_elg = elg_impact * 10\n",
    "        reward = w_sal * r_sal + w_vers * r_vers + w_elg * r_elg\n",
    "        max_q = max(q_vals.values())\n",
    "        old_q = q_vals[p]\n",
    "        q_vals[p] = (1 - lr) * q_vals[p] + lr * (reward + gamma * max_q)\n",
    "        \n",
    "    return q_vals, old_q\n",
    "\n",
    "def get_feedback(rec):\n",
    "    global progs\n",
    "    fb = {p: int(input(f\"Rate {p} (0-5): \")) for p in rec}\n",
    "    for p, score in fb.items():\n",
    "        if score == 0:\n",
    "            progs.remove(p)\n",
    "            del q_vals[p]\n",
    "        else:\n",
    "            q_vals[p] += f_adj * (score - 2) * 5\n",
    "\n",
    "max_ep = 10\n",
    "for ep in range(max_ep):\n",
    "    u_s = ask_qs()\n",
    "    q_vals, old_q = update_q_vals()\n",
    "    epsilon=abs(q_vals-old_q)\n",
    "    print(q_vals, old_q)\n",
    "    if len(progs) < top_n:\n",
    "        break\n",
    "    \n",
    "    if epsilon < epsilon_threshold:\n",
    "        rec = sorted(q_vals, key=q_vals.get, reverse=True)[:top_n]\n",
    "        get_feedback(rec)\n",
    "        satisfied = input(\"Satisfied? (yes/no): \").strip().lower()\n",
    "\n",
    "        if satisfied == 'yes':\n",
    "            break\n",
    "\n",
    "if len(progs) >= top_n:\n",
    "    print(\"\\nFinal Recommendations:\")\n",
    "    rec = sorted(q_vals, key=q_vals.get, reverse=True)[:top_n]\n",
    "    for i, p in enumerate(rec, 1):\n",
    "        print(f\"{i}. {p}\")\n",
    "else:\n",
    "    print(\"\\nNot enough programs left to recommend. Test ends.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Define parameters\n",
    "n_items = 1000  # Total number of items\n",
    "n_traits = 6    # Number of latent traits\n",
    "n_adaptive = 30  # Number of adaptive steps\n",
    "\n",
    "# Distribution of item types: 40% Likert, 20% Binary, 20% Value, 10% Single MC, 10% Multiple MC\n",
    "n_likert = int(0.3 * n_items)\n",
    "n_binary = int(0.2 * n_items)\n",
    "n_value = int(0.2 * n_items)\n",
    "n_mc_single = int(0.15 * n_items)\n",
    "n_mc_multi = int(0.15 * n_items)\n",
    "\n",
    "# Assign item types\n",
    "item_types = (['likert'] * n_likert + ['binary'] * n_binary + ['value'] * n_value +\n",
    "              ['mc_single'] * n_mc_single + ['mc_multi'] * n_mc_multi)\n",
    "np.random.shuffle(item_types)\n",
    "\n",
    "# 2. Simulate latent traits for a respondent, bounded in [-3, 3]\n",
    "true_th = np.random.uniform(-3, 3, size=n_traits)\n",
    "\n",
    "# 3. Randomly initialize item parameters\n",
    "a_params = np.random.randn(n_items, n_traits)  # Discrimination parameters for all items\n",
    "thresholds = [np.sort(np.random.uniform(-2, 2, size=4)) for _ in range(n_items)]  # Thresholds for ordinal items\n",
    "binary_b = np.random.randn(n_items)  # Difficulty parameters for binary items\n",
    "value_thresh = np.sort(np.random.uniform(-2, 2, size=5))  # Thresholds for value items (0-5)\n",
    "mc_params = np.random.randn(n_items, n_traits, 4)  # Discrimination params for multiple-choice\n",
    "\n",
    "# 4. Define probability functions for GPCM\n",
    "\n",
    "def gpcm_prob(a, th, thresholds):\n",
    "    diff = np.dot(a, th)\n",
    "    category_probs = []\n",
    "    for k in range(len(thresholds) + 1):\n",
    "        if k == 0:\n",
    "            category_probs.append(1)\n",
    "        else:\n",
    "            category_probs.append(np.exp(np.sum(diff - thresholds[:k])))\n",
    "    denom = np.sum(category_probs)\n",
    "    return np.array(category_probs) / denom\n",
    "\n",
    "# Binary Logistic Model\n",
    "def bin_prob(a, b, th):\n",
    "    prob = expit(np.dot(a, th) - b)\n",
    "    return prob\n",
    "\n",
    "# Nominal Response Model for single multiple-choice\n",
    "def mc_single_prob(a, th):\n",
    "    exponent = np.dot(a.T, th)\n",
    "    numerator = np.exp(exponent)\n",
    "    return numerator / np.sum(numerator)\n",
    "\n",
    "# Nominal Response Model for multiple multiple-choice\n",
    "def mc_multi_prob(a, th):\n",
    "    probs = expit(np.dot(a.T, th))\n",
    "    return np.clip(probs, 0, 1)\n",
    "\n",
    "# 5. Simulate responses for different item types\n",
    "def sim_response(item_type, q):\n",
    "    if item_type == \"binary\":\n",
    "        prob = bin_prob(a_params[q], binary_b[q], true_th)\n",
    "        return np.random.binomial(1, prob)\n",
    "    elif item_type == \"likert\":\n",
    "        probs = gpcm_prob(a_params[q], true_th, thresholds[q])\n",
    "        return np.argmax(np.random.multinomial(1, probs)) + 1\n",
    "    elif item_type == \"value\":\n",
    "        probs = gpcm_prob(a_params[q], true_th, value_thresh)\n",
    "        return np.argmax(np.random.multinomial(1, probs))\n",
    "    elif item_type == \"mc_single\":\n",
    "        probs = mc_single_prob(mc_params[q], true_th)\n",
    "        return np.argmax(np.random.multinomial(1, probs))\n",
    "    elif item_type == \"mc_multi\":\n",
    "        probs = mc_multi_prob(mc_params[q], true_th)\n",
    "        return np.random.binomial(1, probs)\n",
    "\n",
    "# 6. Define log-likelihood function\n",
    "def log_likelihood(params, responses, selected_items):\n",
    "    th = params[:n_traits]\n",
    "    ll = 0\n",
    "    for i, q in enumerate(selected_items):\n",
    "        item_type = item_types[q]\n",
    "        if item_type == \"binary\":\n",
    "            prob = bin_prob(a_params[q], binary_b[q], th)\n",
    "            prob = np.clip(prob, 1e-8, 1 - 1e-8)\n",
    "            ll += responses[i] * np.log(prob) + (1 - responses[i]) * np.log(1 - prob)\n",
    "        elif item_type == \"likert\":\n",
    "            probs = gpcm_prob(a_params[q], th, thresholds[q])\n",
    "            selected_category = responses[i] - 1\n",
    "            ll += np.log(probs[selected_category])\n",
    "        elif item_type == \"value\":\n",
    "            probs = gpcm_prob(a_params[q], th, value_thresh)\n",
    "            ll += np.log(probs[responses[i]])\n",
    "        elif item_type == \"mc_single\":\n",
    "            probs = mc_single_prob(mc_params[q], th)\n",
    "            ll += np.log(probs[responses[i]])\n",
    "        elif item_type == \"mc_multi\":\n",
    "            probs = mc_multi_prob(mc_params[q], th)\n",
    "            for j in range(len(responses[i])):\n",
    "                ll += responses[i][j] * np.log(probs[j]) + (1 - responses[i][j]) * np.log(1 - probs[j])\n",
    "    return -ll\n",
    "\n",
    "# 7. Define adaptive testing function\n",
    "def adaptive_test(n_adaptive_steps=5, noise_factor=0.1):\n",
    "    est_theta = np.zeros(n_traits)\n",
    "    selected_items = []\n",
    "    responses = []\n",
    "    information_gain = []\n",
    "    \n",
    "    bounds = [(-3, 3)] * n_traits  # Bound for latent traits\n",
    "    \n",
    "    for step in range(n_adaptive_steps):\n",
    "        infos = []\n",
    "        for i in range(n_items):\n",
    "            if i in selected_items:\n",
    "                infos.append(-np.inf)\n",
    "                continue\n",
    "            item_type = item_types[i]\n",
    "            if item_type == \"binary\":\n",
    "                prob = bin_prob(a_params[i], binary_b[i], est_theta)\n",
    "                info = prob * (1 - prob)\n",
    "            elif item_type == \"likert\":\n",
    "                probs = gpcm_prob(a_params[i], est_theta, thresholds[i])\n",
    "                info = np.sum(probs * (1 - probs))\n",
    "            elif item_type == \"value\":\n",
    "                probs = gpcm_prob(a_params[i], est_theta, value_thresh)\n",
    "                info = np.sum(probs * (1 - probs))\n",
    "            elif item_type == \"mc_single\":\n",
    "                probs = mc_single_prob(mc_params[i], est_theta)\n",
    "                info = np.sum(probs * (1 - probs))\n",
    "            elif item_type == \"mc_multi\":\n",
    "                probs = mc_multi_prob(mc_params[i], est_theta)\n",
    "                info = np.sum(probs * (1 - probs))\n",
    "            infos.append(info)\n",
    "        \n",
    "        # Add noise to the information gain\n",
    "        infos = np.array(infos) + np.random.randn(len(infos)) * noise_factor\n",
    "        \n",
    "        # Select the item with the highest information\n",
    "        next_item = np.argmax(infos)\n",
    "        selected_items.append(next_item)\n",
    "        \n",
    "        # Simulate the response\n",
    "        resp = sim_response(item_types[next_item], next_item)\n",
    "        responses.append(resp)\n",
    "        \n",
    "        # Collect information gain\n",
    "        information_gain.append(infos[next_item])\n",
    "        \n",
    "        # Update latent traits using MLE\n",
    "        res = minimize(log_likelihood, est_theta, args=(responses, selected_items),\n",
    "                      method='L-BFGS-B', bounds=bounds)\n",
    "        est_theta = res.x[:n_traits]\n",
    "        \n",
    "        print(f\"Step {step+1}: Selected Item {next_item+1}, Response: {resp}, Estimated Theta: {est_theta}\")\n",
    "    \n",
    "    return est_theta, information_gain, selected_items\n",
    "\n",
    "# 8. Run the adaptive test\n",
    "final_theta, information_gain, selected_items = adaptive_test(n_adaptive_steps=5)\n",
    "\n",
    "# 9. Generate meaningful plots\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Information Gain During Adaptive Testing\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(information_gain, marker='o', linestyle='-', color='b')\n",
    "plt.title(\"Information Gain During Adaptive Testing\")\n",
    "plt.xlabel(\"Test Step\")\n",
    "plt.ylabel(\"Information Gain\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Final Latent Trait Estimates vs True Traits\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_traits):\n",
    "    plt.scatter([i+1], [true_th[i]], color='green', label='True Trait' if i == 0 else \"\")\n",
    "    plt.scatter([i+1], [final_theta[i]], color='red', label='Estimated Trait' if i == 0 else \"\")\n",
    "plt.title(\"Final Latent Trait Estimates vs True Traits\")\n",
    "plt.xlabel(\"Trait Number\")\n",
    "plt.ylabel(\"Trait Value\")\n",
    "plt.xticks(range(1, n_traits + 1))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test0 = AdaptiveMIRT(select_noise=0.0)\n",
    "# test1 = AdaptiveMIRT(select_noise=0.05)\n",
    "# test2 = AdaptiveMIRT(select_noise=0.1)\n",
    "# test3 = AdaptiveMIRT(select_noise=0.15)\n",
    "# test4 = AdaptiveMIRT(select_noise=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IRT import AdaptiveMIRT\n",
    "\n",
    "tests = []\n",
    "for i in range(5):\n",
    "    t0 = AdaptiveMIRT(select_noise=round(0.05*i, 2))\n",
    "    tests.append(t0)\n",
    "\n",
    "\n",
    "\n",
    "# Select items and simulate responses\n",
    "for x in range(100):\n",
    "    \n",
    "    for _ in range(3):\n",
    "        for test in tests:\n",
    "            test.next_item()\n",
    "            test.sim_resp()\n",
    "\n",
    "        # Update the estimated theta values after responses\n",
    "    for test in tests:\n",
    "        test.update_theta()\n",
    "\n",
    "# Plot the results\n",
    "for test in tests:\n",
    "    test.plot_results(no_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    test.plot_results(no_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests[2].plot_results(save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    print(test.select_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirt_test2 = AdaptiveMIRT(select_noise=0.05)\n",
    "\n",
    "# Select items and simulate responses\n",
    "for x in range(100):\n",
    "    for _ in range(3):\n",
    "        mirt_test2.next_item()\n",
    "        mirt_test2.sim_resp()\n",
    "\n",
    "    # Update the estimated theta values after responses\n",
    "    mirt_test2.update_theta()\n",
    "\n",
    "# Plot the results\n",
    "mirt_test2.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steph\\Documents\\RecSys\\model\\agent.py:102: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  states = torch.FloatTensor([entry[0] for entry in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Total Reward: -2103.069879005208\n",
      "Episode 2, Total Reward: -2015.9834542557235\n",
      "Episode 3, Total Reward: -2225.2478931633696\n",
      "Episode 4, Total Reward: -2200.6451834694653\n",
      "Episode 5, Total Reward: -1891.7920339954262\n",
      "Episode 6, Total Reward: -1681.6728538330512\n",
      "Episode 7, Total Reward: -2227.062027948529\n",
      "Episode 8, Total Reward: -2224.1519514610272\n",
      "Episode 9, Total Reward: -2003.2800888574027\n",
      "Episode 10, Total Reward: -2012.8739614544356\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):  \u001b[38;5;66;03m# Assuming a maximum of 100 steps per episode\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     action, logits \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mselect_action(state)\n\u001b[1;32m---> 18\u001b[0m     next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     buffer\u001b[38;5;241m.\u001b[39madd(state, action, reward, next_state, done)\n\u001b[0;32m     21\u001b[0m     episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[1;32mc:\\Users\\steph\\Documents\\RecSys\\model\\env.py:30\u001b[0m, in \u001b[0;36mVocRecEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mnext\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mnext_item()\n\u001b[0;32m     29\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39msim_resp()\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_theta\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_reward(feedback, job_rank)\n\u001b[0;32m     34\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_observation()\n",
      "File \u001b[1;32mc:\\Users\\steph\\Documents\\RecSys\\model\\IRT.py:122\u001b[0m, in \u001b[0;36mAdaptiveMIRT.update_theta\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_theta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 122\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mest_th\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mest_th \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mx[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_traits]\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mth_hist\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mest_th\u001b[38;5;241m.\u001b[39mcopy())\n",
      "File \u001b[1;32mc:\\Users\\steph\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:731\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    728\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    729\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 731\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    734\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    735\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\steph\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:347\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    344\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    353\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32mc:\\Users\\steph\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:288\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    284\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32mc:\\Users\\steph\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:222\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    219\u001b[0m     finite_diff_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_linear_operator\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# Initial function evaluation\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Initial gradient evaluation\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_grad, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ngev \u001b[38;5;241m=\u001b[39m _wrapper_grad(\n\u001b[0;32m    226\u001b[0m     grad,\n\u001b[0;32m    227\u001b[0m     fun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_fun,\n\u001b[0;32m    228\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    229\u001b[0m     finite_diff_options\u001b[38;5;241m=\u001b[39mfinite_diff_options\n\u001b[0;32m    230\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\steph\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 294\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32mc:\\Users\\steph\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\steph\\Documents\\RecSys\\model\\IRT.py:39\u001b[0m, in \u001b[0;36mAdaptiveMIRT.log_like\u001b[1;34m(self, th, item)\u001b[0m\n\u001b[0;32m     37\u001b[0m ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msel_items):\n\u001b[1;32m---> 39\u001b[0m     ll \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_item_log_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mll\n",
      "File \u001b[1;32mc:\\Users\\steph\\Documents\\RecSys\\model\\IRT.py:52\u001b[0m, in \u001b[0;36mAdaptiveMIRT._item_log_like\u001b[1;34m(self, th, item, resp)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resp \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(prob) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m resp) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m prob)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m it_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlikert\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 52\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpcm_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthresholds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(probs \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m probs)) \u001b[38;5;28;01mif\u001b[39;00m resp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlog(probs[resp \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m it_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\steph\\Documents\\RecSys\\model\\IRT.py:109\u001b[0m, in \u001b[0;36mAdaptiveMIRT.gpcm_prob\u001b[1;34m(self, a, th, thresholds)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpcm_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, a, th, thresholds):\n\u001b[1;32m--> 109\u001b[0m     diff \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     probs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m [np\u001b[38;5;241m.\u001b[39mexp(diff \u001b[38;5;241m-\u001b[39m thresholds[k]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(thresholds))]\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(probs) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(probs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from env import VocRecEnv\n",
    "from agent import PPOAgent\n",
    "from utils import ReplayBuffer\n",
    "\n",
    "env = VocRecEnv()\n",
    "agent = PPOAgent(env)\n",
    "buffer = ReplayBuffer()\n",
    "\n",
    "num_episodes = 100\n",
    "batch_size = 32\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "\n",
    "    for step in range(100):  # Assuming a maximum of 100 steps per episode\n",
    "        action, logits = agent.select_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        buffer.add(state, action, reward, next_state, done)\n",
    "        episode_reward += reward\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if len(buffer.buffer) >= batch_size:\n",
    "            agent.update(buffer, batch_size)\n",
    "            buffer.clear()\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # print(f\"Episode {episode + 1}, Total Reward: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "m = nn.Softmax(dim=1)\n",
    "input = torch.randn(2, 3)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = buffer.sample(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "states = torch.FloatTensor([entry[0] for entry in batch])  # Extract states as-is\n",
    "actions = torch.LongTensor([entry[1] for entry in batch])  # Actions\n",
    "rewards = torch.FloatTensor([entry[2] for entry in batch])  # Rewards\n",
    "next_states = torch.FloatTensor([entry[3] for entry in batch])  # Next states as-is\n",
    "dones = torch.FloatTensor([entry[4] for entry in batch])  # Done flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.view(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.flatten(obs, start_dim=1)\n",
    "x1 = torch.nn.functional.relu(agent.actor.fc1(x0))\n",
    "x2 = agent.actor.fc2(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = agent.actor(obs)\n",
    "ps = torch.softmax(ls, dim=-1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for idx in range(len(jr)):\n",
    "    dff = np.abs(env.ability-jr[idx]).mean()\n",
    "\n",
    "    if dff>1:\n",
    "        fbs.append(-1)\n",
    "    else:\n",
    "        fbb = 1 - (dff/ (env.ability_range[1]-env.ability_range[0]))\n",
    "        fbb = max(0.5, fbb)\n",
    "        fbs.append(fbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.job_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.random.uniform(*env.ability_range, size=(env.n_jobs, env.n_traits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = np.concatenate(([env.ability], x2)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
